{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c179c5-5864-4563-a6d9-42ce3b6ca177",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how \n",
    "can they be mitigated?\n",
    "<br>Ans. When the model performs well on  training data but performs poorly on testing data, then it is known as overfitting.\n",
    "And when the model can't perform well on both training and testing data, then it is known asÂ underfitting.\n",
    "<br>Underfitting can be mitigated by increasing the model complexity and Overfitting can be mitigated by increasing the training data and reducing model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d913c-1e85-429b-bec6-f776c7fc3814",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief.\n",
    "<br>Ans. Overfitting can be reduced by various techniques:\n",
    "1. By Increasing the training data: This helps the model generalize better and reduces the chance of memorizing outliers in existing data.\n",
    "2. Model simplification: Sometimes, by reducing the model's complexity can reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c41d8d-7b2c-43aa-ac56-569528812b88",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "<br>Ans. When a model performs well only on training but fails to perform on test data, then it is said that algorithm has underfitting. There are many reason from which underfitting can occur but some main reasons are:\n",
    "<br>The size of the training dataset may not be sufficient or the model would be too simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077870a-73c1-4719-aa57-f1e48e96a37e",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?\n",
    "<br>Ans. The Bias and variance tradeoff is a fundamental concept of machine learning that relates to the performance of model. It involves balancing two sources of errors: bias and variance\n",
    "<br>Bias: It is the difference between average prediction of model and correct value which we are trying to predict. Model with high bias pays very little attention to training data. It always leads to high error on training and test data.\n",
    "<br>Variance: It is the variability of model prediction for a given data point which tells us about the spread of the data. Models with high variance performs well on training data but can't perform well on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24170e2-20b3-42c1-a1df-61648babf07b",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?\n",
    "<br>Ans. There are several ways to detect overfitting or underfitting in a machine learning model. One way is to plot the learning curves, which show the model's performance on training and validation data over time as model is being trained. Another method is to evaluate the model on a holdout dataset, which is a subset of the data that is not used during training but is used to test the model after training.\n",
    "<br>We can identify if a machine learning model has overfit by first evaluating the model on training dataset and then evaluating the same model on holdout training dataset. If the model significantly performs better on training data than the test data, then the model may have overfitted.\n",
    "<br>On the other hand, if the model performs poorly on both testing and training data, then it is likely underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b33fa9-3f3f-4c73-af51-df7927c771b4",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?\n",
    "<br>Ans. Low bias, high variance: If a model has low bias and high variance, then it is overfitting. For example, If we prepared well for exam but failed to score good in exam.\n",
    "<br>High bias, high variance: If a model has bias and high variance, then it is underfitting. For example, If we don't prepare well for exam and we fail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e8b00-8d60-48e4-811b-bea2e2d47413",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work.\n",
    "<br>Ans. Regularization is a technique in machine learning used to prevent overfitting and improve the model's ability to generalize the new data.\n",
    "<br>L1 regularization (Lasso regression) and L2 regularization (Ridge regression) are some common regularization techniques.\n",
    "<br>L1 regularization: It adds the penalty to the model's cost function(difference between predicted values and actual values) proportional to the absolute values of model's coefficients. This encourages the model to have smaller coefficients, which can help to prevent overfitting.\n",
    "<br>L2 regularization: It adds the penalty to the model's cost function proportional to the squares of model's coefficients. This "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
