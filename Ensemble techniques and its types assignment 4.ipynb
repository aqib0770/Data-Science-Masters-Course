{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15341170-2b62-4037-8140-bb0452a48852",
   "metadata": {},
   "source": [
    "Q1. What is Random Forest Regressor?\n",
    "<br>Ans: Random forest aggressor is a type of ensemble learning model that uses decision trees as base learners. It works by training multiple decision trees on bootstrap samples of the training data. The predictions of the individual trees are then averaged to produce the final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4163f9-420d-480c-87de-8de527fc2468",
   "metadata": {},
   "source": [
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "<br>Ans: Random forest regressors reduce the risk of overfitting in several ways:\n",
    "- Bootstrap sampling: Bootstrap sampling helps to reduce the overfitting by training each decision tree on a different subset of the data. This means that each decision tree is less likely to overfit the training data.\n",
    "- Eandom feature selection: Random forest regressors randomly select a subset of features to consider when making each split in a decision tree. This helps to reduce overfitting by preventing the decision trees from becoming too complex and memorizing the training data.\n",
    "- Ensemble averaging: The predictions of the individual decision trees are averaged to produce the final prediction of the random forest regressor. This helps to reduce overfitting by averaging out the errors of the individual decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b7c7f-3d33-4efb-a268-51b790eff03f",
   "metadata": {},
   "source": [
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "<br>Ans: Random forest regressor aggregates the predictions of multiple decision trees by averaging them. This is done to reduce the variance of the predictions and improve the overall accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327c1a5-9e78-40b7-b6ee-61a44125264d",
   "metadata": {},
   "source": [
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "<br>Ans: The hyperparameters of a random forest regressor are:\n",
    "- Number of trees: The number of trees in the random forest regressor.\n",
    "- Maximum depth: The maximum depth of each tree in the random forest regressor.\n",
    "- Minimum sample split: The minimum number of samples required to split a node in a decision tree.\n",
    "- Minimum sample leaf: The minimum number of samples required in a leaf node of a decision tree.\n",
    "- Random feature selection: The number of features to consider when making each split in a decision tree.\n",
    "- Criterion: The criterion used to measure the quality of split in a decision tree. The most common criterion is Gini impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f80c0a-804f-4129-bba5-c0a2e0c9c166",
   "metadata": {},
   "source": [
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "1. Random forest regressor is an ensemble learning algorithm while decision tree regressor is a single model algorithm.\n",
    "2. random forest regressor uses bagging while decision tree regressor dosen't.\n",
    "3. Random forest regressor is more robuts to overfitting than decision tree regressor.\n",
    "4. Random forest regressor is computationally expensive than Decision Tree Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e631b627-08a7-4e99-ad71-09c0671485bf",
   "metadata": {},
   "source": [
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "#### Advantages:\n",
    "- Robust to overfitting: Random forest regressors are relatively robust to overfitting, which means that they are less likely to learn the training data too well and make poor predictions on new data.\n",
    "- Easy to interpret: The predictions of random forest regressors can be easily interpreted by looking at the predictions of the individual decision trees. This can be helpful for understanding why the model made a particular predictio\n",
    "#### Disadvantages:\n",
    "- Computationally expensive: Random forest regressors can be computationally expensive to train, especially for large data sets.\n",
    "- Sensitive to hyperparameters: The performance of random forest regressors can be sensitive to the choice of hyperparameters, such as the number of trees and the maximum depth of the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2eaef-eebd-4dce-9898-3f2ce50c1e0c",
   "metadata": {},
   "source": [
    "Q7. What is the output of Random Forest Regressor?\n",
    "<br>The output of a random forest regressor is the predicted value of the target variable for a new data point. The predicted value is calculated by averaging the predictions of the individual decision trees in the random forest.\n",
    "<br>In the case of a regression task, the target variable is a continuous value, such as the price of a house or the number of sales made. The predicted value is also a continuous value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171b981-3e0d-4315-a860-bbc05254c963",
   "metadata": {},
   "source": [
    "Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "<br>Ans: No, random forest regressor cannot be used for classification tasks. Random forest regressor is an algorithm that is used to predict a continuous numerical value from a set of features. In contrast, a classification algorithm is used to predict a categorical value from a set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137ca92-25ae-4ed5-90ec-9c627e01aa58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
