{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7055386f-3ccb-491e-ae26-d7bbf7a0673d",
   "metadata": {},
   "source": [
    "Q1. What is anomaly detection and what is its purpose?\n",
    "<br>Ans: Anomaly is a technique used in Machine Learning to detect outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751c6a24-1dc2-4b22-b597-6514d02de842",
   "metadata": {},
   "source": [
    "Q2. What are the key challenges in anomaly detection?\n",
    "- Interpretability: It can be difficult to interpret the results of anomaly detection. This can make it difficult to understand why the model identified a particular data point as an anomaly and take appropriate action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708460b0-3657-4221-acdc-c186cc5f9ba5",
   "metadata": {},
   "source": [
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "- Unsupervised anomaly detection does not require labelled data while Supervised anomaly detection required labelled data.\n",
    "- Unsupervised learning is difficult to interpret while supervised learning is easy to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc4181-a0af-40df-abd2-d7e27140765c",
   "metadata": {},
   "source": [
    "Q4. What are the main categories of anomaly detection algorithms?\n",
    "<br>Ans: The main categories of anomaly detection are as follows:\n",
    "- Statistical anomaly detection: These algorithms use statistical methods to identify data points that deviate significantly from normal behaviour of data. Examples of statistical algorithms are Z-score test, Interquartile range.\n",
    "- Distance based anomaly detection: These algorithms identify data points that are far away from most other data points. Examples of Distance based anomaly detection are KNN(K-nearest neighbours), Local outlier, Isolation forest.\n",
    "- Clustering based anomaly detection: These algorithms identify data points that no longer belong to any of the clusters. Examples of Clustering based algorithms include K-means clustering, Hierarchical clustering, DBSCAN clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d130f92b-0d9a-4ffa-85a8-be6adb0ea246",
   "metadata": {},
   "source": [
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "- Anomalies are rare: Distance based anomaly detection method work best when anomalies are rare. If there are too many anomalies, the method may not be able to accurately identify them.\n",
    "- Anomalies are far away from normal data points: Distance based anomaly detection methods identify anomalies by finding data points that are far away from most other data points. This means that the methods may not be able to identify anomalies that are closer to normal data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0839dcc-ef1f-413f-b55b-a45e13860998",
   "metadata": {},
   "source": [
    "Q6. How does the LOF algorithm compute anomaly scores?\n",
    "<br>Ans: The LOF(Local Outlier Factor) algorithms computes anomaly scores by comparing local density of a data point to the local density of its neighbours. The local density of a data point is measured by the reachibility distance to its k-nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64913c-2901-495b-84fd-0dd01fd5c69f",
   "metadata": {},
   "source": [
    "Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "<br>Ans: The key parameters of Isolation Forest algorithm are:\n",
    "- n_estimators: The number of isolation forest to construct. More trees will lead to more accurate results, but will also have threat of overfitting.\n",
    "- max_samples: The maximum number of samples to use to train each isolation tree. A similat value will lead to faster training and prediction, but may also make the algorithm more sensitive to noise.\n",
    "- contamination: The expected proportion of outliers in the data. This parameter is used to determine the threshold for anomaly scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a9a03d-8d1c-4511-b5d8-c954138eee4f",
   "metadata": {},
   "source": [
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
    "<br>Ans: The anomaly score of a data point in KNN is calculated by averaging the distance to its K nearest neighbors. If a data point has only 2 neighbors of the same class within a radius of 0.5, then its other 8 nearest neighbors must be of a different class. This means that the data point likely to be an outlier and its anomaly score will be high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181059d9-a714-4dfd-a252-43628467a3de",
   "metadata": {},
   "source": [
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the\n",
    "anomaly score for a data point that has an average path length of 5.0 compared to the average path\n",
    "length of the trees?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
